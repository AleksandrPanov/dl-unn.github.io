{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "from numpy.random import rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult(a, b, res):\n",
    "    n = len(a)\n",
    "    m = len(b)\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            res[i,j] = a[i]*b[j]\n",
    "\n",
    "class CrossEntropy:\n",
    "    def __init__(self, num_classes, batch = 1, eps = 1e-18):\n",
    "        self.num_classes = num_classes\n",
    "        self.drop_grad = np.zeros(self.num_classes, dtype='float32')\n",
    "        self.batch = batch\n",
    "        self.eps = eps\n",
    "    def calc(self, X, class_labels):\n",
    "        self.X = X\n",
    "        if self.batch == 1:\n",
    "            label = class_labels\n",
    "            self.labels = [class_labels]\n",
    "            return -np.log(X[label]+self.eps)\n",
    "        else:\n",
    "            self.labels = class_labels\n",
    "    def grad(self):\n",
    "        for label in self.labels:\n",
    "            self.drop_grad[label] = -1.0/(self.X[label]*self.batch)\n",
    "        return self.drop_grad\n",
    "    \n",
    "class SoftMax:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.tmp = np.empty((n,n), dtype='float32')\n",
    "        self.softmax = np.empty(n, dtype='float32')\n",
    "    def calc(self, X):\n",
    "        self.softmax = np.exp(X)\n",
    "        self.softmax /= np.sum(self.softmax)\n",
    "        return self.softmax\n",
    "    def grad(self, vec_top_grad):\n",
    "        mult(-self.softmax, self.softmax, self.tmp)\n",
    "        self.tmp[np.diag_indices_from(self.tmp)] = self.softmax*(1.0-self.softmax)\n",
    "        return np.dot(vec_top_grad, self.tmp)\n",
    "    \n",
    "def initW(n_input, n_output):\n",
    "    return (2*rand(n_input*n_output).reshape(n_input,n_output)).astype('float32'), (2*rand(n_output)).astype('float32')\n",
    "\n",
    "class Net:\n",
    "    coeff = [0.1]\n",
    "    def __init__(self, layers, num_classes):\n",
    "        self.layers = layers\n",
    "        self.n_layers = len(layers)\n",
    "        self.cross = CrossEntropy(num_classes)\n",
    "    def calc(self, x):\n",
    "        res = None\n",
    "        for layer in self.layers:\n",
    "            res = layer.calc(x)\n",
    "            x = res\n",
    "        return res\n",
    "    def fit(self, X, Y, n):\n",
    "        for it in range(n):\n",
    "            for x,y in zip(X,Y):\n",
    "                res = self.calc(x)\n",
    "                # cross res\n",
    "                self.cross.calc(res, y)\n",
    "                gr = self.cross.grad()\n",
    "                for layer in reversed(self.layers):\n",
    "                    gr = layer.grad(gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'coeff'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f3e023eaa144>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0ml1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFullConnected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minitW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[0ml2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFullConnected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minitW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'coeff'"
     ]
    }
   ],
   "source": [
    "class FullConnected:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.n_input = len(W)\n",
    "        self.n_output = len(b)\n",
    "        self.new_grad = np.zeros((self.n_input,self.n_output), dtype='float32')\n",
    "        self.res = np.zeros(self.n_output, dtype='float32')\n",
    "    def calc(self, x):\n",
    "        self.x = x\n",
    "        #vec(x)*matr(W)=vec(y)        \n",
    "        np.dot(x, self.W,  out=self.res)\n",
    "        self.res += self.b\n",
    "        return self.res\n",
    "    def grad(self, vec_top_grad):\n",
    "        # поиск производной выхода y по входу x: d(y)/d(x)\n",
    "        next_grad = np.dot(self.W, vec_top_grad) #порядок умножения?\n",
    "        \n",
    "        # поиск производной по W\n",
    "        mult(self.x, vec_top_grad, self.new_grad)\n",
    "        self.W -= Net.coeff*self.new_grad #0.1 коэффициент градиентного спуска\n",
    "        \n",
    "        # поиск производной по b\n",
    "        self.b -= Net.coeff*vec_top_grad\n",
    "        return next_grad\n",
    "\n",
    "#grad_softmax([1,1,1],[1,-1,0])\n",
    "num_classes = 4\n",
    "cross = CrossEntropy(num_classes)\n",
    "\n",
    "x = np.array([1.,0.5]).astype('float32')\n",
    "label = 1\n",
    "np.random.seed(0)\n",
    "l1 = FullConnected(*initW(2,3))\n",
    "l2 = FullConnected(*initW(3,num_classes))\n",
    "print(l1.W)\n",
    "softmax = SoftMax(num_classes)\n",
    "\n",
    "res1 = l1.calc(x)\n",
    "res2 = l2.calc(res1)\n",
    "res = softmax.calc(res2)\n",
    "print('res = ',res, '\\n\\n')\n",
    "cross.calc(res, label)\n",
    "\n",
    "gr1 = cross.grad()\n",
    "print('gr1 =',gr1)\n",
    "gr2 = softmax.grad(gr1)\n",
    "print('gr2 =',gr2)\n",
    "gr3 = l2.grad(gr2)\n",
    "print('gr3 =',gr3)\n",
    "gr4 = l1.grad(gr3)\n",
    "print(gr4)\n",
    "\n",
    "\n",
    "print('res')\n",
    "res1 = l1.calc(x)\n",
    "res2 = l2.calc(res1)\n",
    "res = softmax.calc(res2)\n",
    "print(res)\n",
    "cross.calc(res, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "cross = CrossEntropy(num_classes)\n",
    "\n",
    "x = np.array([1.,0.5], dtype='float32')\n",
    "label = 1\n",
    "np.random.seed(0)\n",
    "l1 = FullConnected(*initW(2,3))\n",
    "l2 = FullConnected(*initW(3,num_classes))\n",
    "softmax = SoftMax(num_classes)\n",
    "\n",
    "net = Net([l1,l2, softmax],num_classes)\n",
    "net.fit([x], [label], 3200)\n",
    "print(net.calc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
