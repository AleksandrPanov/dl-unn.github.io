{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "import numba as nb\n",
    "from numba import njit, prange\n",
    "import numpy as np\n",
    "from numpy.random import rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True, parallel=True)\n",
    "def mult(a, b, res):\n",
    "    n = len(a)\n",
    "    m = len(b)\n",
    "    for i in prange(n):\n",
    "        for j in range(m):\n",
    "            res[i,j] = a[i]*b[j]\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.sigmoid = np.empty(n, dtype='float32')\n",
    "    def calc(self, X):\n",
    "        self.sigmoid = 1.0/(1.0+np.exp(-X))\n",
    "        return self.sigmoid\n",
    "    def grad(self, vec_top_grad):\n",
    "        return vec_top_grad*self.sigmoid*(1.0-self.sigmoid)\n",
    "\n",
    "class LeakyReLU:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.alpha = 0.1\n",
    "        self.LeakyReLU = np.empty(n, dtype='float32')\n",
    "    def calc(self, X):\n",
    "        self.LeakyReLU = np.where(X>0,X, self.alpha*X)\n",
    "        return self.LeakyReLU\n",
    "    def grad(self, vec_top_grad):\n",
    "        return vec_top_grad*np.where(self.LeakyReLU>0, 1.0, self.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy:\n",
    "    def __init__(self, num_classes, batch = 1, eps = 1e-8):\n",
    "        self.num_classes = num_classes\n",
    "        self.drop_grad = np.zeros(self.num_classes, dtype='float32')\n",
    "        self.batch = batch\n",
    "        self.eps = eps\n",
    "    def calc(self, X, label):\n",
    "        #print(X)\n",
    "        self.X = X.clip(min=self.eps, max=1.0)\n",
    "        #print(self.X)\n",
    "        return -np.log(X[label])\n",
    "    def grad(self, label):\n",
    "        self.drop_grad.fill(0.0)\n",
    "        self.drop_grad[label] = -1.0/self.X[label]\n",
    "        return self.drop_grad\n",
    "    \n",
    "class SoftMax:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.tmp = np.empty((n,n), dtype='float32')\n",
    "        self.softmax = np.empty(n, dtype='float32')\n",
    "    def calc(self, X):\n",
    "        print('x in softmax', max(X))\n",
    "        self.softmax = np.exp(X)\n",
    "        self.softmax /= np.sum(self.softmax)\n",
    "        return self.softmax\n",
    "    def grad(self, vec_top_grad):\n",
    "        mult(-self.softmax, self.softmax, self.tmp)\n",
    "        self.tmp[np.diag_indices_from(self.tmp)] = self.softmax*(1.0-self.softmax)\n",
    "        return np.dot(vec_top_grad, self.tmp)\n",
    "    \n",
    "def initW(n_input, n_output):\n",
    "    tmp1 = np.random.normal(0.0, 2.0/(n_input+n_output), size=n_input*n_output)\n",
    "    tmp1 = tmp1.reshape(n_input,n_output).astype('float32')\n",
    "    tmp2 = np.random.normal(0.0, 2.0/(n_output+n_output), size=n_output).astype('float32')\n",
    "    return tmp1, tmp2\n",
    "\n",
    "class Net:\n",
    "    const_coeff = 0.5\n",
    "    coeff = 0.5\n",
    "    def __init__(self, layers, num_classes):\n",
    "        self.layers = layers\n",
    "        self.n_layers = len(layers)\n",
    "        self.cross = CrossEntropy(num_classes)\n",
    "    def calc(self, x):\n",
    "        res = None\n",
    "        for layer in self.layers:\n",
    "            res = layer.calc(x)\n",
    "            #print(res)\n",
    "            x = res\n",
    "        return res\n",
    "    def get_class(self, x):\n",
    "        res = self.calc(x)\n",
    "        return np.argmax(res), res\n",
    "    def fit(self, X, Y, n):\n",
    "        Net.coeff = Net.const_coeff\n",
    "        for it in range(n):\n",
    "            print('EPOCH',it+1)\n",
    "            for x,y in zip(X,Y):\n",
    "                res = self.calc(x)\n",
    "                # cross res\n",
    "                self.cross.calc(res, y)\n",
    "                gr = self.cross.grad(y)\n",
    "                #print('cross-grad',max(abs(gr)))\n",
    "                max_gr = max(abs(gr))\n",
    "                for layer in reversed(self.layers):\n",
    "                    gr = layer.grad(gr)\n",
    "                    #print('grad',max(abs(gr)))\n",
    "                    max_gr = max(max_gr, max(abs(gr)))\n",
    "                Net.coeff *= 0.9\n",
    "                #print('max_grad',max_gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullConnected:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.n_input = len(W)\n",
    "        self.n_output = len(b)\n",
    "        self.new_grad = np.zeros((self.n_input,self.n_output), dtype='float32')\n",
    "        self.res = np.zeros(self.n_output, dtype='float32')\n",
    "    def calc(self, x):\n",
    "        self.x = x\n",
    "        #vec(x)*matr(W)=vec(y)\n",
    "        self.res = np.dot(x, self.W)\n",
    "        self.res += self.b\n",
    "        print('max W, b, res',np.max(self.W), np.max(self.b), np.max(self.res))\n",
    "        return self.res\n",
    "    def grad(self, vec_top_grad):\n",
    "        # поиск производной выхода y по входу x: d(y)/d(x)\n",
    "        next_grad = np.dot(self.W, vec_top_grad) #порядок умножения?\n",
    "        \n",
    "        # поиск производной по W\n",
    "        mult(self.x, vec_top_grad, self.new_grad)\n",
    "        self.W -= Net.coeff*self.new_grad #0.1 коэффициент градиентного спуска\n",
    "        \n",
    "        # поиск производной по b\n",
    "        self.b -= Net.coeff*vec_top_grad\n",
    "        return next_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n",
      "max W, b, res 0.7469644 0.36356837 1.0853066\n",
      "max W, b, res 0.56743866 0.3831948 0.86027646\n",
      "x in softmax 0.86027646\n",
      "EPOCH 2\n",
      "max W, b, res 0.59923625 0.22504447 0.94593054\n",
      "max W, b, res 0.38492867 0.7732025 1.4644704\n",
      "x in softmax 1.4644704\n",
      "EPOCH 3\n",
      "max W, b, res 0.6299235 0.3210662 1.1619794\n",
      "max W, b, res 0.5296237 0.93698287 2.105098\n",
      "x in softmax 2.105098\n",
      "EPOCH 4\n",
      "max W, b, res 0.67275286 0.38251776 1.3002454\n",
      "max W, b, res 0.6214872 1.0160407 2.5296335\n",
      "x in softmax 2.5296335\n",
      "EPOCH 5\n",
      "max W, b, res 0.7121374 0.4219023 1.3888606\n",
      "max W, b, res 0.67879534 1.0601156 2.8139892\n",
      "x in softmax 2.8139892\n",
      "EPOCH 6\n",
      "max W, b, res 0.7394201 0.44918498 1.4502467\n",
      "max W, b, res 0.7179721 1.0883234 3.017518\n",
      "x in softmax 3.017518\n",
      "EPOCH 7\n",
      "max W, b, res 0.75952095 0.46928582 1.4954736\n",
      "max W, b, res 0.7466084 1.1080692 3.1711216\n",
      "x in softmax 3.1711216\n",
      "EPOCH 8\n",
      "max W, b, res 0.774986 0.4847509 1.53027\n",
      "max W, b, res 0.76852375 1.1227237 3.291481\n",
      "x in softmax 3.291481\n",
      "EPOCH 9\n",
      "max W, b, res 0.7872585 0.49702334 1.557883\n",
      "max W, b, res 0.7858485 1.134045 3.388371\n",
      "x in softmax 3.388371\n",
      "EPOCH 10\n",
      "max W, b, res 0.7972224 0.5069872 1.5803018\n",
      "max W, b, res 0.7998737 1.1430477 3.4679441\n",
      "x in softmax 3.4679441\n",
      "max W, b, res 0.8054538 0.5152186 1.5988224\n",
      "max W, b, res 0.8114341 1.150363 3.5343018\n",
      "x in softmax 3.5343018\n",
      "[0.00793694 0.96533245 0.01551619 0.01121438]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03528273"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 4\n",
    "cross = CrossEntropy(num_classes)\n",
    "\n",
    "x = np.array([1.,0.5], dtype='float32')\n",
    "label = 1\n",
    "np.random.seed(0)\n",
    "l1 = FullConnected(*initW(2,4))\n",
    "l2 = FullConnected(*initW(4,num_classes))\n",
    "softmax = SoftMax(num_classes)\n",
    "\n",
    "net = Net([l1,l2, softmax],num_classes)\n",
    "net.fit([x], [label], 10)\n",
    "res = net.calc(x)\n",
    "print(res)\n",
    "cross.calc(res, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "data = unpickle('data/data_batch_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])\n",
      "3072\n",
      "<class 'numpy.ndarray'>\n",
      "[9]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "print(data.keys())\n",
    "start, end = 2, 3\n",
    "img_ars = data[b'data'][start:end]\n",
    "img_labels = data[b'labels'][start:end]\n",
    "print(len(img_ars[0]))\n",
    "print(type(img_ars[0]))\n",
    "img_ars = img_ars\n",
    "for img_ar,i in zip(img_ars, range(start,end)):\n",
    "    img = Image.fromarray(np.transpose(np.reshape(img_ar,(3, 32,32)), (1,2,0)), 'RGB')\n",
    "    img.save(str(i)+'.png')\n",
    "print(img_labels)"
   ]
  },
  {
   "attachments": {
    "1.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1.png](attachment:1.png)"
   ]
  },
  {
   "attachments": {
    "2.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAH5UlEQVR4nI1WWY9cRxU+51TdrXu6e3pmPONlbA0OUYRIQIqEIiWELAgJCUdBIHjigReExH+CF955AUFEECI4ODhxEtszjpdxbM/mWXq793bfrZZzeGgH8WLk0lWVrkr1bVXSOSgizAzPMgQQsSrK0Xi4tNT3pk5aLRVGgsSA6imHNAAQ0TMRAABAU2bj/Qd7t7MsL157+/vdJAYgBHwahAYAEXkmAyKEcrT38OZH/7RVGSz0qzzrLi0xoCA9DYIAAJ9tAIptysd7O91Wcv7MGrlmdHgA3oOAyFNBnjWcufzxePTo0e7B4eDoeDQbD+/c+Hx8cgIgIPK0GJ49fRHxB/v7D3f3r16/df3WdlnMDnd3Nq99Us0KRQSI/4eAAQTgfyTMNbEX4a92kNlZZ6dlvX88vnV/d+d4VBXFnU8+3r2zxWJZRBjAAwgIAAjPP/0E78mCT/5k7tkhECDiE3l4YWOj1enmRQVIW3sniY50bW5d+WD53Fp//SI6QUEBZJL/Xjp9NSMAogAKgAiwMHtjjMjc3NyD6vdXvvu9N9fOnKsqMx6X93ePstrs3N3e/OBfTT4VFE8iKAjgQByIf0IgOCeY54IgXtz2/Xu3b99ujGHhuWkWxaBffe31H73zThTGvpbdQbp9Mppl9d3L1x58ftODm0JVce25GRfDw8nB3mBHAwCL4Dx075AAEPcOdv/45z/lefbq8OStN96OoohFGMB5Xuh0Lr176f7de3/7y/u5dXcOjvqYxDX9+72/6uUFWlss0ixgf5jvZ9Osruv5HXhAmkxG2WSMCo8GJx9d+/jTWzfycdpY882XXlw9taKUzqdlmqYb6+tn11d/+atf7B18efXGzaZQ2/tHrdNqtLVV/gGee+3lyWxalnmDqbENs2iAhtkDQpYPL1/5cOfx/jBPJ8WU2mHctE9Gw8tXLm9snI+i6GB/YI2pynQ2TQMN3/jOxev3N81U9tO8FUbrvfjhtc9URHR2KXOlAgAJm6bBrS+uah1YYyZp+tmNzc27d3qry07j8sqpwZeHt7c2z51b63UTpVVjxDS1+DogOLu+GvWCa5dvff7hXfaqpeDbi+1+t6NWeumpeEwcmNhZV5alvvLxlSov2nH70qV3nUSfbt7pdfoV12dX1+xxlRVluX23H1G7117on4rb3FtUvW63211IFlpvvv1KNsy2th54i7tpHQSBPnLTiXOdhJKVg73DPC/0g0cPspPJ8197Pknajx+f7DzcXWgnjS0xr6rUAeHXn7v43Klep989Ocn6S3TmfHualyFDzKp7qveDH741nuTH+yfDhltZvtrtapRznaX22umDR49MOdVFlpV1FbXibJrt7D1a7HV9UWPdHB7dP3w8RGp+/tOf8Gz89w//sXPzYLkXHm3jubMXMnsMwcnS8tpLL7xofqx/99vfV9P6cToDHTaGZ8PR2V43TIKV1UX89W9+Ns6m62fOb1y4+N77H6Bg4HiwsxcwWPZ4uvf6G680+XBr+26x70Lyi8txu9XJs6K/mBgPErWT7vLm7e3h4Ug1Lgm0RNhaWTh9ftUzK6V1b6lnCfJZ/sX168cPHxLolg5CCsUYAlw/c26p05+U1cWNF3b8JB2PfLR4XNRl6dPxMSpV4yQtv6QwYRVKqEpg77gdJgu9vlLE4vXCUk932mZUDO/tnV/oIYXTqq7JYRJHqAbH40+v3ljrdEaTNKuqGUM1zAFQqzAJpDZmkKaeVEsnSESxAmAQWxRVnlf95UVg1BySeAwVBdZf6C45UtOqUt0FCuPqOGvScjqaDpnSptx4+VtHg1E6yRYW2nVZ2CCuG1dZJsI4jAWtB1ZakxNmPhmkzoMOkdJ0mk5yY+TU6bOG4d6DnUGaUZxQq1UwN1byWTOYzKrKD46GRVaIlVbUIlQYxU4HYbutwrBuDAMbZxgljKNOp9tqLVgr7FBDFUADDsNCwSGqQ8czwzDKVFCWzMJYOSfiwyA8GAydZwQcTCaAKN4HSdINQ++8iChNCQSkKAhCDENhRkWEWmsMrMisasZ5PjaNC7Q4VVc1NsYKE6l2r6uUUloLgYgopZRSREgETERKKc2evRCSUkSEiIDE7J0D55yeTWd5XhSzqihqROgudqMkAgAkSnQYhJFSKgi00tozi8yLESgiQPHeO+dExDrnQZRWWmsRieM4CrSwj6JID0cja3xdG2NMEAdBHFZVRYqIFJASQecdaUpaERKBiGeGeSMCCABlWXrvdaCFEIkQUUQAEATiOImiSFtrQEjrIIogShJAQA1KKRbwgt57RUqFigIKdSAi3vt5A8EeiGhxcdFa2xjjUebozjnnLHgLIN57vby8TBB4L9axR6nrChUiEjMbz4oVwJzPW8dz1YjALM559qK0cs5Z5yw7UmrOoZQiEO89M+tut8seQagxNi9nOlAqUN578BAQOWb2nsUDEgoCz2unsGcBYmFTGWstgwChADCzgLTiONSKELXWGoEQxdimbiprDSmlicSzca5xHgmRaD6xm6cLDCCInlmQSWOggnldFxHvhQVAmJBA2FmvmblpjLXGmNo0xljHwgiolIqjiLTyzs07cCSFgEQUKgUAdV075xSRUkpEmqYpywoR4zhWRM40hBTHkbbWWmuccyCitQZSCKCUIiIhtM5prb33CKJUQPQkZWEOw5CI5jRBEMyPzB9uGEetqIUAiPgfxCJRYo/3RuEAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2.png](attachment:2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n",
      "EPOCH 1\n",
      "max W, b, res 0.0028345326 0.015343387 0.061227813\n",
      "max W, b, res 0.026923034 0.064989544 0.06586914\n",
      "x in softmax 0.06586914\n",
      "EPOCH 2\n",
      "max W, b, res 0.01111435 0.018527998 10.792968\n",
      "max W, b, res 0.035471484 0.33206314 8.240567\n",
      "x in softmax 8.240567\n",
      "EPOCH 3\n",
      "max W, b, res 0.011135978 0.018541088 10.818428\n",
      "max W, b, res 0.039393324 0.33272022 11.358049\n",
      "x in softmax 11.358049\n",
      "EPOCH 4\n",
      "max W, b, res 0.01113665 0.018541435 10.819224\n",
      "max W, b, res 0.03948948 0.33273625 11.43447\n",
      "x in softmax 11.43447\n",
      "EPOCH 5\n",
      "max W, b, res 0.011137209 0.018541722 10.819875\n",
      "max W, b, res 0.039568994 0.33274952 11.49766\n",
      "x in softmax 11.49766\n",
      "EPOCH 6\n",
      "max W, b, res 0.011137678 0.018541962 10.820437\n",
      "max W, b, res 0.03963552 0.3327606 11.550531\n",
      "x in softmax 11.550531\n",
      "EPOCH 7\n",
      "max W, b, res 0.011138078 0.018542167 10.820899\n",
      "max W, b, res 0.039691914 0.33277 11.59535\n",
      "x in softmax 11.59535\n",
      "EPOCH 8\n",
      "max W, b, res 0.011138421 0.018542342 10.821302\n",
      "max W, b, res 0.0397402 0.33277804 11.633727\n",
      "x in softmax 11.633727\n",
      "EPOCH 9\n",
      "max W, b, res 0.011138717 0.018542493 10.821656\n",
      "max W, b, res 0.039781865 0.33278498 11.666845\n",
      "x in softmax 11.666845\n",
      "EPOCH 10\n",
      "max W, b, res 0.011138974 0.018542625 10.821964\n",
      "max W, b, res 0.039817978 0.332791 11.695555\n",
      "x in softmax 11.695555\n",
      "max W, b, res 0.011139198 0.018542739 10.822224\n",
      "max W, b, res 0.039849374 0.33279625 11.720501\n",
      "x in softmax 11.720501\n",
      "\n",
      "\n",
      "class, res 9 0.9999737 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.6285994e-05"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 10\n",
    "n_input = len(img_ars[0])\n",
    "\n",
    "cross = CrossEntropy(num_classes)\n",
    "x = (img_ars/255.0).astype('float32')\n",
    "labels = img_labels\n",
    "print(labels)\n",
    "np.random.seed(0)\n",
    "l1 = FullConnected(*initW(n_input, 256))\n",
    "#leakyReLU = LeakyReLU(256)\n",
    "l2 = FullConnected(*initW(256, num_classes))\n",
    "softmax = SoftMax(num_classes)\n",
    "\n",
    "net = Net([l1, l2, softmax],num_classes)\n",
    "net.fit(x, labels, 10)\n",
    "vx, vl = x[0], 0\n",
    "calc_class, res = net.get_class(vx)\n",
    "print('\\n\\nclass, res',calc_class, max(res), labels[0])\n",
    "cross.calc(res, labels[vl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3.]\n",
      "[4]\n",
      "[1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "class test:\n",
    "    def __init__(self):\n",
    "        self.x = np.array([1, 2, 3], dtype='float32')\n",
    "    def get(self):\n",
    "        return self.x\n",
    "obj = test()\n",
    "tmp = obj.get()\n",
    "print(tmp)\n",
    "tmp = [4]\n",
    "print(tmp)\n",
    "print(obj.x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
