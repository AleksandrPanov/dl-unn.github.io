{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "from numpy.random import rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult(a, b, res):\n",
    "    n = len(a)\n",
    "    m = len(b)\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            res[i,j] = a[i]*b[j]\n",
    "\n",
    "class CrossEntropy:\n",
    "    def __init__(self, num_classes, batch = 1, eps = 1e-18):\n",
    "        self.num_classes = num_classes\n",
    "        self.drop_grad = np.zeros(self.num_classes, dtype='float32')\n",
    "        self.batch = batch\n",
    "        self.eps = eps\n",
    "    def calc(self, X, class_labels):\n",
    "        self.X = X\n",
    "        if self.batch == 1:\n",
    "            label = class_labels\n",
    "            self.labels = [class_labels]\n",
    "            return -np.log(X[label]+self.eps)\n",
    "        else:\n",
    "            self.labels = class_labels\n",
    "    def grad(self):\n",
    "        for label in self.labels:\n",
    "            self.drop_grad[label] = -1.0/(self.X[label]*self.batch)\n",
    "        return self.drop_grad\n",
    "    \n",
    "class SoftMax:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.tmp = np.empty((n,n), dtype='float32')\n",
    "        self.softmax = np.empty(n, dtype='float32')\n",
    "    def calc(self, X):\n",
    "        self.softmax = np.exp(X)\n",
    "        self.softmax /= np.sum(self.softmax)\n",
    "        return self.softmax\n",
    "    def grad(self, vec_top_grad):\n",
    "        mult(-self.softmax, self.softmax, self.tmp)\n",
    "        self.tmp[np.diag_indices_from(self.tmp)] = self.softmax*(1.0-self.softmax)\n",
    "        return np.dot(vec_top_grad, self.tmp)\n",
    "    \n",
    "def initW(n_input, n_output):\n",
    "    return (2*rand(n_input*n_output).reshape(n_input,n_output)).astype('float32'), (2*rand(n_output)).astype('float32')\n",
    "\n",
    "class Net:\n",
    "    def __init__(self, layers, num_classes):\n",
    "        self.layers = layers\n",
    "        self.n_layers = len(layers)\n",
    "        self.cross = CrossEntropy(num_classes)\n",
    "    def calc(self, x):\n",
    "        res = None\n",
    "        for layer in self.layers:\n",
    "            res = layer.calc(x)\n",
    "            x = res\n",
    "        return res\n",
    "    def fit(self, X, Y, n):\n",
    "        for it in range(n):\n",
    "            for x,y in zip(X,Y):\n",
    "                res = self.calc(x)\n",
    "                # cross res\n",
    "                self.cross.calc(res, y)\n",
    "                gr = self.cross.grad()\n",
    "                for layer in reversed(self.layers):\n",
    "                    gr = layer.grad(gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.097627  1.4303787 1.2055267]\n",
      " [1.0897664 0.8473096 1.2917882]]\n",
      "res =  [0.9862742  0.00518497 0.00588081 0.00265998] \n",
      "\n",
      "\n",
      "gr1 = [   0.      -192.86523    0.         0.     ]\n",
      "gr2 = [ 0.9862742  -0.99481505  0.00588081  0.00265998]\n",
      "gr3 = [-0.80964047  1.6855811   0.10957771]\n",
      "[1.6544349 0.6874413]\n",
      "res\n",
      "[5.3978783e-13 9.9999964e-01 2.1849610e-07 1.3972232e-07]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.576279326012052e-07"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FullConnected:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.n_input = len(W)\n",
    "        self.n_output = len(b)\n",
    "        self.new_grad = np.zeros((self.n_input,self.n_output), dtype='float32')\n",
    "        self.res = np.zeros(self.n_output, dtype='float32')\n",
    "    def calc(self, x):\n",
    "        self.x = x\n",
    "        #vec(x)*matr(W)=vec(y)        \n",
    "        np.dot(x, self.W,  out=self.res)\n",
    "        self.res += self.b\n",
    "        return self.res\n",
    "    def grad(self, vec_top_grad):\n",
    "        # поиск производной выхода y по входу x: d(y)/d(x)\n",
    "        next_grad = np.dot(self.W, vec_top_grad) #порядок умножения?\n",
    "        \n",
    "        # поиск производной по W\n",
    "        mult(self.x, vec_top_grad, self.new_grad)\n",
    "        self.W -= 0.5*self.new_grad #0.1 коэффициент градиентного спуска\n",
    "        \n",
    "        # поиск производной по b\n",
    "        self.b -= 0.5*vec_top_grad\n",
    "        return next_grad\n",
    "\n",
    "#grad_softmax([1,1,1],[1,-1,0])\n",
    "num_classes = 4\n",
    "cross = CrossEntropy(num_classes)\n",
    "\n",
    "x = np.array([1.,0.5]).astype('float32')\n",
    "label = 1\n",
    "np.random.seed(0)\n",
    "l1 = FullConnected(*initW(2,3))\n",
    "l2 = FullConnected(*initW(3,num_classes))\n",
    "print(l1.W)\n",
    "softmax = SoftMax(num_classes)\n",
    "\n",
    "res1 = l1.calc(x)\n",
    "res2 = l2.calc(res1)\n",
    "res = softmax.calc(res2)\n",
    "print('res = ',res, '\\n\\n')\n",
    "cross.calc(res, label)\n",
    "\n",
    "gr1 = cross.grad()\n",
    "print('gr1 =',gr1)\n",
    "gr2 = softmax.grad(gr1)\n",
    "print('gr2 =',gr2)\n",
    "gr3 = l2.grad(gr2)\n",
    "print('gr3 =',gr3)\n",
    "gr4 = l1.grad(gr3)\n",
    "print(gr4)\n",
    "\n",
    "\n",
    "print('res')\n",
    "res1 = l1.calc(x)\n",
    "res2 = l2.calc(res1)\n",
    "res = softmax.calc(res2)\n",
    "print(res)\n",
    "cross.calc(res, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.3914978e-13 9.9999964e-01 2.1822309e-07 1.3956264e-07]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 4\n",
    "cross = CrossEntropy(num_classes)\n",
    "\n",
    "x = np.array([1.,0.5], dtype='float32')\n",
    "label = 1\n",
    "np.random.seed(0)\n",
    "l1 = FullConnected(*initW(2,3))\n",
    "l2 = FullConnected(*initW(3,num_classes))\n",
    "softmax = SoftMax(num_classes)\n",
    "\n",
    "net = Net([l1,l2, softmax],num_classes)\n",
    "net.fit([x], [label], 100)\n",
    "print(net.calc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 y1\n",
      "x2 y2\n"
     ]
    }
   ],
   "source": [
    "np.random.rand(4).reshape(2,2)\n",
    "A,B = ['x1','x2'],['y1', 'y2']\n",
    "for a,b in zip(A,B):\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
